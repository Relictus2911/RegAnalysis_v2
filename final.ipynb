{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": "import re\nimport pymorphy2\nfrom nltk.corpus import stopwords\nfrom pandas import read_csv, DataFrame\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.pipeline import FeatureUnion, Pipeline\nfrom sklearn.preprocessing import StandardScaler, FunctionTransformer\nfrom sklearn.svm import SVR\nimport matplotlib.pyplot as plt\n\nmorph \u003d pymorphy2.MorphAnalyzer()\nstops \u003d set(stopwords.words(\"english\")) | set(stopwords.words(\"russian\"))\n\ndef normalize(text):\n    new_text \u003d re.sub(\"[^а-яА-Яa-zA-Z]\", \" \", text)\n    # lower case\n    words \u003d new_text.lower().split()\n    # remove stop words\n    words \u003d [w for w in words if not w in stops]\n    # normal form\n    words \u003d [morph.parse(w)[0].normal_form for w in words]\n    return (words)\n\ndef get_name(reg_model):\n     name \u003d str(reg_model.named_steps[\u0027Reg\u0027])\n     name \u003d name[:name.index(\u0027(\u0027)]\n     return name\n    \ndef show_most_informative_features(reg_model):    \n    if(get_name(reg_model) \u003d\u003d \u0027LinearRegression\u0027):\n        feature_names \u003d reg_model.named_steps[\u0027union\u0027].transformer_list[0][1].named_steps[\u0027count_vect\u0027].get_feature_names()\n        scaler \u003d StandardScaler()\n        coefs_help \u003d reg_model.named_steps[\u0027Reg\u0027].coef_\n        scaler.fit(coefs_help)\n        blabla \u003d scaler.transform(coefs_help)\n        feature_names.append(\u0027coms\u0027)\n        feature_names.append(\u0027favs\u0027)\n        feature_names.append(\u0027size\u0027)\n        coefs_with_fns \u003d sorted(zip(blabla, feature_names), reverse\u003dTrue)\n        print(DataFrame(coefs_with_fns[:10],columns \u003d [\u0027feature\u0027, \u0027coefs\u0027]))\n\ndef reg_methods(reg_model): \n    model \u003d {}\n    model[\u0027name\u0027] \u003d get_name(reg_model)\n    X \u003d data.drop([\u0027likes\u0027],axis\u003d1)\n    Y \u003d data[\u0027likes\u0027]\n    x_train, x_test, y_train, y_test \u003d train_test_split(X, Y, test_size\u003d0.4)\n    reg_model.fit(x_train,y_train)        \n    model[\u0027score\u0027] \u003d reg_model.score(x_test,y_test)\n    show_most_informative_features(reg_model)\n    return model\n\n    \n\ndef paint_reg_methods(test_models): # Построение графика\n        fig, axes \u003d plt.subplots(figsize\u003d(16, 4))\n        test_models.score.plot(kind\u003d\u0027barh\u0027, title\u003d\u0027Regression Methods\u0027, fontsize\u003d10, stacked\u003dTrue)\n        fig.savefig(\u0027result.png\u0027)\n\ndataset \u003d read_csv(\u0027test.tsv\u0027,sep \u003d\u0027\\t\u0027,error_bad_lines\u003dFalse)\ndata \u003d DataFrame(dataset, columns\u003d[\u0027likes\u0027,\u0027coms\u0027,\u0027favs\u0027,\u0027size\u0027,\u0027text\u0027])"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "print(dataset.corr())\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "source": "class ItemSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, key):\n        self.key \u003d key\n\n    def fit(self, x, y\u003dNone):\n        return self\n\n    def transform(self, data_frame):\n        return data_frame[[self.key]]   \nclass Converter(BaseEstimator, TransformerMixin):\n    def fit(self, x, y\u003dNone):\n        return self\n\n    def transform(self, data_frame):\n        return data_frame.values.ravel()\n    \nlin_reg \u003d Pipeline([(\u0027union\u0027, FeatureUnion(\n                transformer_list\u003d[(\u0027text_vect\u0027, Pipeline([(\u0027selector\u0027, ItemSelector(key\u003d\u0027text\u0027)),\n                                                            (\u0027converter\u0027, Converter()),\n                                                          (\u0027count_vect\u0027, TfidfVectorizer(tokenizer\u003dnormalize,stop_words \u003d stops))])),\n                                 (\u0027coms_sc\u0027, Pipeline([(\u0027selector\u0027, ItemSelector(key\u003d\u0027coms\u0027)),\n                                                           (\u0027std_scaler\u0027,  StandardScaler())])),\n                                 (\u0027favs_sc\u0027,Pipeline([(\u0027selector\u0027, ItemSelector(key\u003d\u0027favs\u0027)),\n                                                           (\u0027std_scaler\u0027,  StandardScaler())])),\n                                 (\u0027size_sc\u0027,Pipeline([(\u0027selector\u0027, ItemSelector(key\u003d\u0027size\u0027)),\n                                                           (\u0027std_scaler\u0027,  StandardScaler())]))],\n                transformer_weights\u003d{\u0027text_vect\u0027: 1.0,\u0027coms_sc\u0027: 1.0,\u0027favs_sc\u0027: 1.0,\u0027size_sc\u0027: 1.0 })),\n\n                          (\u0027Reg\u0027, LinearRegression())])\nrand_fores_reg \u003d Pipeline([(\u0027union\u0027, FeatureUnion(\n                transformer_list\u003d[(\u0027text_vect\u0027, Pipeline([(\u0027selector\u0027, ItemSelector(key\u003d\u0027text\u0027)),\n                                                            (\u0027converter\u0027, Converter()),\n                                                          (\u0027count_vect\u0027, TfidfVectorizer(tokenizer\u003dnormalize,stop_words \u003d stops))])),\n                                 (\u0027coms_sc\u0027, Pipeline([(\u0027selector\u0027, ItemSelector(key\u003d\u0027coms\u0027)),\n                                                           (\u0027std_scaler\u0027,  StandardScaler())])),\n                                 (\u0027favs_sc\u0027,Pipeline([(\u0027selector\u0027, ItemSelector(key\u003d\u0027favs\u0027)),\n                                                           (\u0027std_scaler\u0027,  StandardScaler())])),\n                                 (\u0027size_sc\u0027,Pipeline([(\u0027selector\u0027, ItemSelector(key\u003d\u0027size\u0027)),\n                                                           (\u0027std_scaler\u0027,  StandardScaler())]))],\n                transformer_weights\u003d{\u0027text_vect\u0027: 1.0,\u0027coms_sc\u0027: 1.0,\u0027favs_sc\u0027: 1.0,\u0027size_sc\u0027: 1.0 })),\n                          (\u0027Reg\u0027, RandomForestRegressor(n_estimators\u003d10, max_features\u003d\u0027sqrt\u0027))])\nkneigh_reg \u003d Pipeline([(\u0027union\u0027, FeatureUnion(\n                transformer_list\u003d[(\u0027text_vect\u0027, Pipeline([(\u0027selector\u0027, ItemSelector(key\u003d\u0027text\u0027)),\n                                                            (\u0027converter\u0027, Converter()),\n                                                          (\u0027count_vect\u0027, TfidfVectorizer(tokenizer\u003dnormalize,stop_words \u003d stops))])),\n                                 (\u0027coms_sc\u0027, Pipeline([(\u0027selector\u0027, ItemSelector(key\u003d\u0027coms\u0027)),\n                                                           (\u0027std_scaler\u0027,  StandardScaler())])),\n                                 (\u0027favs_sc\u0027,Pipeline([(\u0027selector\u0027, ItemSelector(key\u003d\u0027favs\u0027)),\n                                                           (\u0027std_scaler\u0027,  StandardScaler())])),\n                                 (\u0027size_sc\u0027,Pipeline([(\u0027selector\u0027, ItemSelector(key\u003d\u0027size\u0027)),\n                                                           (\u0027std_scaler\u0027,  StandardScaler())]))],\n                transformer_weights\u003d{\u0027text_vect\u0027: 1.0,\u0027coms_sc\u0027: 1.0,\u0027favs_sc\u0027: 1.0,\u0027size_sc\u0027: 1.0 })),\n                          (\u0027Reg\u0027, KNeighborsRegressor(n_neighbors\u003d6))])\nsvr_reg \u003d Pipeline([(\u0027union\u0027, FeatureUnion(\n                transformer_list\u003d[(\u0027text_vect\u0027, Pipeline([(\u0027selector\u0027, ItemSelector(key\u003d\u0027text\u0027)),\n                                                            (\u0027converter\u0027, Converter()),\n                                                          (\u0027count_vect\u0027, TfidfVectorizer(tokenizer\u003dnormalize,stop_words \u003d stops))])),\n                                 (\u0027coms_sc\u0027, Pipeline([(\u0027selector\u0027, ItemSelector(key\u003d\u0027coms\u0027)),\n                                                           (\u0027std_scaler\u0027,  StandardScaler())])),\n                                 (\u0027favs_sc\u0027,Pipeline([(\u0027selector\u0027, ItemSelector(key\u003d\u0027favs\u0027)),\n                                                           (\u0027std_scaler\u0027,  StandardScaler())])),\n                                 (\u0027size_sc\u0027,Pipeline([(\u0027selector\u0027, ItemSelector(key\u003d\u0027size\u0027)),\n                                                           (\u0027std_scaler\u0027,  StandardScaler())]))],\n                transformer_weights\u003d{\u0027text_vect\u0027: 1.0,\u0027coms_sc\u0027: 1.0,\u0027favs_sc\u0027: 1.0,\u0027size_sc\u0027: 1.0 })),\n                          (\u0027Reg\u0027,SVR(kernel\u003d\u0027linear\u0027))])\n\n\n\ntest_models \u003d DataFrame()",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m\u003cipython-input-3-6585a08cb5f2\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[1;34m\u001b[0m\n\u001b[1;32m----\u003e 1\u001b[1;33m \u001b[0mtest_models\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mtest_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreg_methods\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlin_reg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#bla \u003d test_models.named_steps[\u0027Reg\u0027].coef_[:-3]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m\u003cipython-input-1-57d2f4a2cc65\u003e\u001b[0m in \u001b[0;36mreg_methods\u001b[1;34m(reg_model)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mreg_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\u0027score\u0027\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mreg_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---\u003e 56\u001b[1;33m     \u001b[0mshow_most_informative_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreg_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m\u003cipython-input-1-57d2f4a2cc65\u003e\u001b[0m in \u001b[0;36mshow_most_informative_features\u001b[1;34m(reg_model)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mscaler\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mcoefs_help\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mreg_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\u0027Reg\u0027\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---\u003e 40\u001b[1;33m         \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoefs_help\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0mblabla\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoefs_help\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mfeature_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\u0027coms\u0027\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\admin\\pycharmprojects\\reg_analysis_v2\\venv\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--\u003e 639\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\admin\\pycharmprojects\\reg_analysis_v2\\venv\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    661\u001b[0m         X \u003d check_array(X, accept_sparse\u003d(\u0027csr\u0027, \u0027csc\u0027), copy\u003dself.copy,\n\u001b[0;32m    662\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--\u003e 663\u001b[1;33m                         force_all_finite\u003d\u0027allow-nan\u0027)\n\u001b[0m\u001b[0;32m    664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m         \u001b[1;31m# Even in the case of `with_mean\u003dFalse`, we update the mean anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\admin\\pycharmprojects\\reg_analysis_v2\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    519\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--\u003e 521\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[1;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray\u003d[12.7955247  -2.88085386  6.85987867 ... 32.12323144 39.90287634\n -2.29109495].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ],
          "ename": "ValueError",
          "evalue": "Expected 2D array, got 1D array instead:\narray\u003d[12.7955247  -2.88085386  6.85987867 ... 32.12323144 39.90287634\n -2.29109495].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
          "output_type": "error"
        }
      ],
      "source": "test_models \u003d test_models.append([reg_methods(lin_reg)],sort\u003dTrue)\n#bla \u003d test_models.named_steps[\u0027Reg\u0027].coef_[:-3]",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "test_models \u003d test_models.append([reg_methods(rand_fores_reg)],sort\u003dTrue)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "test_models \u003d test_models.append([reg_methods(kneigh_reg)],sort\u003dTrue)\ntest_models \u003d test_models.append([reg_methods(svr_reg)],sort\u003dTrue)\ntest_models.set_index(\u0027name\u0027,inplace\u003dTrue)\npaint_reg_methods(test_models)\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}